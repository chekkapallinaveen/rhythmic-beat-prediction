{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio file\n",
    "file_repo = '../CMR_subset_1.0/audio'\n",
    "\n",
    "# extract features from all the files in the repo\n",
    "def extract_features(file_repo):\n",
    "  features = []\n",
    "  for file in os.listdir(file_repo):\n",
    "    if file.endswith(\".wav\"):\n",
    "      file_path = os.path.join(file_repo, file)\n",
    "      y, sr = librosa.load(file_path)\n",
    "      chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "      mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "      combined_features = np.vstack((chroma, mfccs)).T\n",
    "      features.append(combined_features)\n",
    "  return features\n",
    "\n",
    "extracted_features = extract_features(file_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../CMR_subset_1.0/CMRdataset.csv'\n",
    "\n",
    "def extract_labels(file_path):\n",
    "  labels = []\n",
    "  with open(file_path, 'r') as f:\n",
    "    # leave out the header\n",
    "    next(f)\n",
    "    for line in f:\n",
    "      line = line.strip()\n",
    "      line = line.split(',')\n",
    "      labels.append(line[-1])\n",
    "  return labels\n",
    "\n",
    "extracted_labels = extract_labels(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(606733, 32)\n"
     ]
    }
   ],
   "source": [
    "extracted_features = np.vstack(extracted_features)\n",
    "\n",
    "print(extracted_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model for Rhythmic beat classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 5168 at dim 1 (got 4180)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/chnaveen/Documents/sem5/music/rhythmic-beat-prediction/scripts/data_processing.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chnaveen/Documents/sem5/music/rhythmic-beat-prediction/scripts/data_processing.ipynb#X16sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chnaveen/Documents/sem5/music/rhythmic-beat-prediction/scripts/data_processing.ipynb#X16sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Assuming your features and labels are NumPy arrays\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/chnaveen/Documents/sem5/music/rhythmic-beat-prediction/scripts/data_processing.ipynb#X16sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m features_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mTensor(extracted_features)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chnaveen/Documents/sem5/music/rhythmic-beat-prediction/scripts/data_processing.ipynb#X16sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m labels_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor(extracted_labels)\u001b[39m.\u001b[39mint()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chnaveen/Documents/sem5/music/rhythmic-beat-prediction/scripts/data_processing.ipynb#X16sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Create a DataLoader for handling batches\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 5168 at dim 1 (got 4180)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming input shape is (5168, 32)\n",
    "input_shape = (5168, 32)\n",
    "\n",
    "# Define the CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    self.conv1 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "    self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "    self.fc1 = nn.Linear(64 * 2582, 64)\n",
    "    self.fc2 = nn.Linear(64, 4)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.pool(F.relu(self.conv1(x)))\n",
    "    x = x.view(-1, 64 * 2582)  # Adjust the view size based on your specific task\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.fc2(x)\n",
    "    return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming your features and labels are NumPy arrays\n",
    "features_tensor = torch.Tensor(extracted_features)\n",
    "labels_tensor = torch.Tensor(extracted_labels).int()\n",
    "\n",
    "# Create a DataLoader for handling batches\n",
    "dataset = TensorDataset(features_tensor, labels_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for inputs, labels in dataloader:\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
